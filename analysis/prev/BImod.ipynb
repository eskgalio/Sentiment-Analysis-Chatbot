{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef8eee47-201f-48cd-a78c-16484245e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0cdd813-e75c-422f-827b-1ac20b7b8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = \"Processed_SentimentData.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7211fc1d-6ab9-46ac-a3f4-cd0dee4bf17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abcd\\AppData\\Local\\Temp\\ipykernel_5888\\3405114471.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numeric values with median\n",
      "C:\\Users\\abcd\\AppData\\Local\\Temp\\ipykernel_5888\\3405114471.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('Unknown', inplace=True)  # Replace missing text with 'Unknown'\n"
     ]
    }
   ],
   "source": [
    "### 1️⃣ Handling Missing Values\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col].fillna('Unknown', inplace=True)  # Replace missing text with 'Unknown'\n",
    "    else:\n",
    "        df[col].fillna(df[col].median(), inplace=True)  # Fill numeric values with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d0b0fd9-f862-47b8-8b98-62c67c8c7992",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2️⃣ Standardizing Column Names\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace(r'[^\\w]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "779914bb-dbc5-423e-9366-c7e0db1a7d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3️⃣ Converting Data Types\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col])  # Convert to numeric if possible\n",
    "        except ValueError:\n",
    "            pass  # Keep as text if conversion fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "331b9e89-53fd-4895-b704-231ac3d22ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abcd\\AppData\\Local\\Temp\\ipykernel_5888\\821254081.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip().lower() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "### 4️⃣ Normalizing Categorical Data\n",
    "df = df.applymap(lambda x: x.strip().lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e007109-9b86-48fe-9afb-a7a031252144",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5️⃣ Date & Time Features\n",
    "date_columns = [col for col in df.columns if 'date' in col or 'time' in col]\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "    # Extract multiple date features\n",
    "    df[f\"{col}_year\"] = df[col].dt.year\n",
    "    df[f\"{col}_month\"] = df[col].dt.month\n",
    "    df[f\"{col}_day\"] = df[col].dt.day\n",
    "    df[f\"{col}_weekday\"] = df[col].dt.weekday\n",
    "    df[f\"{col}_week_number\"] = df[col].dt.isocalendar().week\n",
    "    df[f\"{col}_quarter\"] = df[col].dt.quarter\n",
    "    df[f\"{col}_is_weekend\"] = df[col].dt.weekday.isin([5,6]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dcd49a8-e642-45f4-b538-fc6184babd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 6️⃣ Sentiment Score Processing\n",
    "sentiment_cols = [col for col in df.columns if 'sentiment' in col]\n",
    "for col in sentiment_cols:\n",
    "    df[f\"{col}_scaled\"] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "    df[f\"{col}_category\"] = pd.cut(df[col], bins=[-1, 0.3, 0.7, 1], labels=['negative', 'neutral', 'positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "546188de-148f-4a70-bb32-9e21c63aa16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7️⃣ Text Processing Features\n",
    "text_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in text_cols:\n",
    "    df[f\"{col}_word_count\"] = df[col].apply(lambda x: len(str(x).split()) if isinstance(x, str) else 0)\n",
    "    df[f\"{col}_char_count\"] = df[col].apply(lambda x: len(str(x)) if isinstance(x, str) else 0)\n",
    "    df[f\"{col}_avg_word_length\"] = df[f\"{col}_char_count\"] / (df[f\"{col}_word_count\"] + 1)\n",
    "    df[f\"{col}_special_char_count\"] = df[col].apply(lambda x: sum(1 for char in str(x) if not char.isalnum()) if isinstance(x, str) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a884ed84-8357-4381-9cda-8dad5f1718a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Bin edges must be unique: Index([1.0, 1.0, 1.0, 1.0, 2.0], dtype='float64', name='status_word_count').\nYou can drop duplicate edges by setting the 'duplicates' kwarg",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_log\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog1p(df[col])  \u001b[38;5;66;03m# Log transformation (to reduce skew)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_zscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (df[col] \u001b[38;5;241m-\u001b[39m df[col]\u001b[38;5;241m.\u001b[39mmean()) \u001b[38;5;241m/\u001b[39m df[col]\u001b[38;5;241m.\u001b[39mstd()  \u001b[38;5;66;03m# Standardization (z-score)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_bin\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mqcut(df[col], q\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvery_high\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\tile.py:340\u001b[0m, in \u001b[0;36mqcut\u001b[1;34m(x, q, labels, retbins, precision, duplicates)\u001b[0m\n\u001b[0;32m    336\u001b[0m quantiles \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, q \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m is_integer(q) \u001b[38;5;28;01melse\u001b[39;00m q\n\u001b[0;32m    338\u001b[0m bins \u001b[38;5;241m=\u001b[39m x_idx\u001b[38;5;241m.\u001b[39mto_series()\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mquantile(quantiles)\n\u001b[1;32m--> 340\u001b[0m fac, bins \u001b[38;5;241m=\u001b[39m _bins_to_cuts(\n\u001b[0;32m    341\u001b[0m     x_idx,\n\u001b[0;32m    342\u001b[0m     Index(bins),\n\u001b[0;32m    343\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m    344\u001b[0m     precision\u001b[38;5;241m=\u001b[39mprecision,\n\u001b[0;32m    345\u001b[0m     include_lowest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    346\u001b[0m     duplicates\u001b[38;5;241m=\u001b[39mduplicates,\n\u001b[0;32m    347\u001b[0m )\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _postprocess_for_cut(fac, bins, retbins, original)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\tile.py:443\u001b[0m, in \u001b[0;36m_bins_to_cuts\u001b[1;34m(x_idx, bins, right, labels, precision, include_lowest, duplicates, ordered)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_bins) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m duplicates \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 443\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBin edges must be unique: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(bins)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can drop duplicate edges by setting the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduplicates\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m kwarg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m         )\n\u001b[0;32m    447\u001b[0m     bins \u001b[38;5;241m=\u001b[39m unique_bins\n\u001b[0;32m    449\u001b[0m side: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m right \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Bin edges must be unique: Index([1.0, 1.0, 1.0, 1.0, 2.0], dtype='float64', name='status_word_count').\nYou can drop duplicate edges by setting the 'duplicates' kwarg"
     ]
    }
   ],
   "source": [
    "### 8️⃣ Numerical Feature Enhancements\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "for col in num_cols:\n",
    "    df[f\"{col}_log\"] = np.log1p(df[col])  # Log transformation (to reduce skew)\n",
    "    df[f\"{col}_zscore\"] = (df[col] - df[col].mean()) / df[col].std()  # Standardization (z-score)\n",
    "    df[f\"{col}_bin\"] = pd.qcut(df[col], q=4, labels=['low', 'medium', 'high', 'very_high'])  # Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42eadaab-6e1a-4c03-a62d-0fd7ec8425ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 9️⃣ Binary Flags for Missing Values (Before Filling)\n",
    "for col in df.columns:\n",
    "    df[f\"{col}_missing_flag\"] = df[col].isnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "555b6c5b-2390-4fa4-b472-575c3c42057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 🔟 Optimizing Data Size\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdf5c83e-d0d9-4be9-8890-3aac73441171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Enhanced dataset saved to: PowerBI_Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataset\n",
    "output_path = \"PowerBI_Dataset.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"🚀 Enhanced dataset saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
